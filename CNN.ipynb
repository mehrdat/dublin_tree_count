{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RMtP-jzUkBF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50, decode_predictions\n",
        "from tensorflow.keras.layers import Dense, LSTM,Embedding,Flatten,Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiKiNhomxJ8w"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfvADzP6jDbk"
      },
      "outputs": [],
      "source": [
        "# !rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMMgSTG8Y69Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlr9DQd8oz-0"
      },
      "outputs": [],
      "source": [
        "# # from tensorflow.keras.applications import InceptionV3\n",
        "# # base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "# # from tensorflow.keras.applications import EfficientNetB0\n",
        "# # base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# from tensorflow.keras.applications import Xception\n",
        "# base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# #base_model=VGG16(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
        "\n",
        "# x=base_model.output\n",
        "# #x=Dropout(.1)(x)\n",
        "# x=Flatten()(x)\n",
        "\n",
        "# x=Dense(264,activation='relu')(x)\n",
        "# predictions=Dense(1,activation='linear')(x)\n",
        "# model=Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "# # for layer in base_model.layers:\n",
        "# #   layer.trainable=False\n",
        "\n",
        "# #model_checkpoint_callback=ModelCheckpoint(filepath='trees.keras',monitor='val_loss',save_best_only=True)\n",
        "# early_stopping_callback=EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# tensorboard_callback =TensorBoard(log_dir='logs',histogram_freq=1)\n",
        "\n",
        "\n",
        "# model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# history=model.fit(train_generator,\n",
        "#                   validation_data=validation_generator,\n",
        "#                   epochs=10,\n",
        "#                   #steps_per_epoch=8,\n",
        "#                   callbacks=[tensorboard_callback,model_checkpoint_callback])\n",
        "#                   #early_stopping_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3S6vw1zD5Tl9",
        "outputId": "923de2a3-cc05-4fca-b312-6aebdf782c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikeras[tensorflow]\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting keras>=3.2.0 (from scikeras[tensorflow])\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.4.2 (from scikeras[tensorflow])\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow>=2.16.1 (from scikeras[tensorflow])\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (13.7.1)\n",
            "Collecting namex (from keras>=3.2.0->scikeras[tensorflow])\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (3.9.0)\n",
            "Collecting optree (from keras>=3.2.0->scikeras[tensorflow])\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (3.5.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.2.0)\n",
            "Collecting h5py (from keras>=3.2.0->scikeras[tensorflow])\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (18.1.1)\n",
            "Collecting ml-dtypes (from keras>=3.2.0->scikeras[tensorflow])\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow>=2.16.1->scikeras[tensorflow])\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.37.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.16.1->scikeras[tensorflow]) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras[tensorflow]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow>=2.16.1->scikeras[tensorflow]) (2.1.5)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, scikit-learn, keras, tensorflow, scikeras\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 scikeras-0.13.0 scikit-learn-1.5.0 tensorboard-2.16.2 tensorflow-2.16.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "5bec4f9b728147118ee1fec24c36c6f6",
              "pip_warning": {
                "packages": [
                  "h5py",
                  "keras",
                  "ml_dtypes",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install scikeras[tensorflow]      # gpu compute platform\n",
        "#!pip install scikeras[tensorflow-cpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbJMrS195hYf"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from scikeras.wrappers import KerasRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "Qm-VlrtmG5eQ",
        "outputId": "f893666a-1ed0-4952-d4fa-be62eca2d808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2441c877da76>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mrandom_search_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1928\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1930\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1931\u001b[0m             ParameterSampler(\n\u001b[1;32m   1932\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    912\u001b[0m                     )\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    915\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    916\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         )\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "#from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications import EfficientNetB0,EfficientNetB1,EfficientNetB2,EfficientNetB3\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "\n",
        "\n",
        "# Function to create model, required for KerasRegressor\n",
        "def create_model(learning_rate, neurons):\n",
        "    # Create an Adam optimizer with the given learning rate\n",
        "    opt = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    #base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(neurons, activation='relu')(x)\n",
        "    predictions = Dense(1, activation='linear')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "    return model\n",
        "\n",
        "def generator_to_data(generator):\n",
        "    data_list = []\n",
        "    labels_list = []\n",
        "    for i in range(generator.samples // generator.batch_size):\n",
        "        data, labels = next(generator)\n",
        "        data_list.append(data)\n",
        "        labels_list.append(labels)\n",
        "    return np.concatenate(data_list), np.concatenate(labels_list)\n",
        "\n",
        "# Assuming train_generator is defined elsewhere in your code\n",
        "X_train, y_train = generator_to_data(train_generator)\n",
        "\n",
        "# Create model\n",
        "model = KerasRegressor(build_fn=create_model, verbose=0,\n",
        "                       neurons=32,learning_rate=0.1,\n",
        "                       )\n",
        "\n",
        "# Define the grid search parameters\n",
        "params = {\n",
        "    'neurons': [264,512,1028],\n",
        "    #'activation': ['relu', 'tanh'],\n",
        "    'batch_size': [10,32, 128],\n",
        "    'epochs': [10, 15,20],\n",
        "    'learning_rate': [0.1, 0.01, 0.001]\n",
        "}\n",
        "\n",
        "# Search the grid\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=30, n_jobs=2, cv=3)\n",
        "\n",
        "random_search_result = random_search.fit(X_train, y_train,verbose=True)\n",
        "\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (random_search_result.best_score_, random_search_result.best_params_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkjv-ZLPmfp9"
      },
      "source": [
        "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1052: UserWarning: One or more of the test scores are non-finite: [-1.56665672e+17 -1.61089643e+00            -inf]\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1063: RuntimeWarning: invalid value encountered in subtract\n",
        "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n",
        "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
        "  X, y = self._initialize(X, y)\n",
        "Best: -1.610896 using {'neurons': 264, 'learning_rate': 0.001, 'epochs': 15}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u-hf_IjHXVb"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir=logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM_bPeyE26zr",
        "outputId": "1cc23052-9a08-4549-f1da-f9d892f34ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 23 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Load the CSV file containing image filenames and labels\n",
        "labels = pd.read_csv(\"tree.csv\")\n",
        "\n",
        "# Set the number of augmented images you want to generate\n",
        "num_augmented_images = 1000\n",
        "\n",
        "# Define the image data generator with desired augmentations\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=.1,\n",
        "    zoom_range=.2,\n",
        "    rotation_range=15,\n",
        "    brightness_range=[.7, 1.3],\n",
        "    shear_range=45,\n",
        "    channel_shift_range=100,\n",
        "    rescale=1.0/255\n",
        ")\n",
        "\n",
        "# Define the target size of the images\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Define the directory where the original images are stored\n",
        "data_dir = 'image/'\n",
        "\n",
        "# Create a generator for the training data\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    labels,\n",
        "    directory=data_dir,\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=target_size,\n",
        "    batch_size=1,  # Set to 1 to generate images one by one\n",
        "    class_mode='raw',\n",
        "    shuffle=True  # Shuffle the data\n",
        ")\n",
        "\n",
        "# Function to save generated images to disk\n",
        "def save_augmented_images(generator, num_images, save_dir):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filenames = []\n",
        "    tree_counts = []\n",
        "    for i in range(num_images):\n",
        "        img, label = next(generator)\n",
        "        img_path = os.path.join(save_dir, f\"augmented_image_{i}.png\")\n",
        "        img = img[0]  # Remove batch dimension\n",
        "        img = (img * 255).astype('uint8')  # Rescale back to 0-255\n",
        "        Image.fromarray(img).save(img_path)\n",
        "        filenames.append(f\"augmented_image_{i}.png\")\n",
        "        tree_counts.append(label[0])\n",
        "    return pd.DataFrame({'filenames': filenames, 'tree_count': tree_counts})\n",
        "\n",
        "# Save augmented images to the specified directory\n",
        "augmented_labels = save_augmented_images(train_generator, num_augmented_images, 'augmented_images')\n",
        "\n",
        "# Save the augmented_labels DataFrame to a CSV file\n",
        "augmented_labels.to_csv('augmented_labels.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3KRA00k7pAm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwKZeuVgHvYy",
        "outputId": "149fe1c6-e1b3-4d7a-bac6-2fad70e0fc7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ],
      "source": [
        "%tensorboard --logdir=logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p85EnkM_qMp"
      },
      "source": [
        "# A New Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqO3zuw6c4q6",
        "outputId": "3edb51d5-c8d3-430a-a36b-0cf4dcd1992f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.43.1-py3-none-any.whl (675 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m675.8/675.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.19.2)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet_ml)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.31.0)\n",
            "Collecting semantic-version>=2.8.0 (from comet_ml)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet_ml)\n",
            "  Downloading sentry_sdk-2.6.0-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson (from comet_ml)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.0.7)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.14.1)\n",
            "Collecting wurlitzer>=1.0.2 (from comet_ml)\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (979 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.7.1)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet_ml) (1.16.0)\n",
            "Installing collected packages: everett, wurlitzer, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.2.0\n",
            "    Uninstalling python-box-7.2.0:\n",
            "      Successfully uninstalled python-box-7.2.0\n",
            "Successfully installed comet_ml-3.43.1 configobj-5.0.8 dulwich-0.22.1 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-2.6.0 simplejson-3.19.2 wurlitzer-3.1.1\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4xTGh21ZRzI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD4euVlO_drz",
        "outputId": "188f06c1-fb30-4cb8-e7a6-07f2f753b3eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 41 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Load the CSV file containing image filenames and labels\n",
        "labels = pd.read_csv(\"tree.csv\")\n",
        "\n",
        "# Set the number of augmented images you want to generate\n",
        "num_augmented_images = 2000\n",
        "\n",
        "# Define the image data generator with desired augmentations\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=.1,\n",
        "    zoom_range=.2,\n",
        "    rotation_range=15,\n",
        "    brightness_range=[.7, 1.3],\n",
        "    shear_range=45,\n",
        "    channel_shift_range=100,\n",
        "    rescale=1.0/255\n",
        ")\n",
        "\n",
        "# Define the target size of the images\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Define the directory where the original images are stored\n",
        "data_dir = 'image/'\n",
        "\n",
        "# Create a generator for the training data\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    labels,\n",
        "    directory=data_dir,\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=target_size,\n",
        "    batch_size=1,  # Set to 1 to generate images one by one\n",
        "    class_mode='raw',\n",
        "    shuffle=True  # Shuffle the data\n",
        ")\n",
        "\n",
        "# Function to save generated images to disk\n",
        "def save_augmented_images(generator, num_images, save_dir):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filenames = []\n",
        "    tree_counts = []\n",
        "    for i in range(num_images):\n",
        "        img, label = next(generator)\n",
        "        img_path = os.path.join(save_dir, f\"augmented_image_{i}.png\")\n",
        "        img = img[0]  # Remove batch dimension\n",
        "        img = (img * 255).astype('uint8')  # Rescale back to 0-255\n",
        "        Image.fromarray(img).save(img_path)\n",
        "        filenames.append(f\"augmented_image_{i}.png\")\n",
        "        tree_counts.append(label[0])\n",
        "    return pd.DataFrame({'filenames': filenames, 'tree_count': tree_counts})\n",
        "\n",
        "# Save augmented images to the specified directory\n",
        "augmented_labels = save_augmented_images(train_generator, num_augmented_images, 'augmented_images')\n",
        "\n",
        "# Save the augmented_labels DataFrame to a CSV file\n",
        "augmented_labels.to_csv('augmented_labels.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiRUndiKjaeu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, DepthwiseConv2D, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Rescaling, ZeroPadding2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "def create_model2():\n",
        "    input_layer = Input(shape=(224, 224, 3))\n",
        "    x = Rescaling(1./255)(input_layer)\n",
        "    x = ZeroPadding2D(padding=(2, 2))(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(264, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(1, activation='linear')(x)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=predictions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def create_model(input_shape=(224, 224, 3)):\n",
        "    \"\"\"\n",
        "    Creates a lightweight convolutional neural network (CNN) for tree counting.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple, optional): Input image shape (height, width, channels).\n",
        "            Defaults to (224, 224, 3).\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: Compiled CNN model for tree counting.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1: Feature extraction with efficient depth-wise convolutions\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)  # Reduce spatial resolution\n",
        "\n",
        "    # Block 2: Feature extraction with depth-wise and point-wise convolutions\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters=64, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)  # Reduce spatial resolution\n",
        "\n",
        "    # Block 3: Feature extraction with mixed convolutions\n",
        "    x = layers.Conv2D(filters=128, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters=128, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=2, strides=2)(x)  # Reduce spatial resolution\n",
        "\n",
        "    # Block 4: Feature extraction with efficient convolutions\n",
        "    x = layers.Conv2D(filters=256, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters=256, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Flatten for dense layers\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Dense layers for regression (adjust final activation based on task)\n",
        "    outputs = layers.Dense(1, activation='linear')(x)  # Linear activation for regression\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "    # Compile with appropriate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdCBwT_n_gVX",
        "outputId": "a3907e33-172d-417f-8254-7f5000dca112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 5.25 µs\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Found 1560 validated image filenames.\n",
            "Found 440 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/15\n",
            "12/12 [==============================] - 100s 8s/step - loss: 772.0406 - val_loss: 486.7694 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "12/12 [==============================] - 111s 10s/step - loss: 492.2406 - val_loss: 338.5053 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "12/12 [==============================] - 96s 8s/step - loss: 354.5630 - val_loss: 277.1121 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "12/12 [==============================] - 96s 8s/step - loss: 267.4743 - val_loss: 215.0968 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "12/12 [==============================] - 94s 8s/step - loss: 201.7211 - val_loss: 190.6493 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "12/12 [==============================] - 98s 8s/step - loss: 170.0570 - val_loss: 156.7651 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "12/12 [==============================] - 108s 9s/step - loss: 139.5165 - val_loss: 135.9830 - lr: 0.0010\n",
            "Epoch 8/15\n",
            " 6/12 [==============>...............] - ETA: 34s - loss: 125.6238"
          ]
        }
      ],
      "source": [
        "%time\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0,MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten,Dropout,DepthwiseConv2D,Input,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "\n",
        "# Load the augmented labels CSV file\n",
        "augmented_labels = pd.read_csv('augmented_labels.csv')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_labels, val_labels = train_test_split(augmented_labels, test_size=0.22, random_state=42)\n",
        "\n",
        "# Define the image data generator for rescaling (no further augmentation needed for training and validation)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Create a generator for the augmented training data\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_labels,\n",
        "    directory='augmented_images',\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=128,  # Use a larger batch size for training\n",
        "    class_mode='raw',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Create a generator for the validation data\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    val_labels,\n",
        "    directory='augmented_images',\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='raw',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "#base_model=create_model()\n",
        "\n",
        "\n",
        "# Model\n",
        "#InceptionV3\n",
        "\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model(inputs)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "#x = layers.Dense(256, activation='relu')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "\n",
        "predictions = Dense(1, activation='linear')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#print(model.summary())\n",
        "#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "#CallBacks\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0000001)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=15,\n",
        "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
        "    callbacks=[tensorboard_callback,reduce_lr_callback]#, early_stopping_callback]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13A3wR2WKJ6E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtjv4VY_ZXC9"
      },
      "outputs": [],
      "source": [
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT1cC76UAlOU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC1kTcUBOvK_"
      },
      "outputs": [],
      "source": [
        "model.save('inception_epoch_30.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7VsVJg0Aoo1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import  load_img,img_to_array\n",
        "from PIL import Image\n",
        "\n",
        "with Image.open('test_image/test.jpg') as img:\n",
        "  test_image=img.resize((224,224))\n",
        "  test_image = test_image.convert('RGB')\n",
        "#test_image=load_img('image/test.jpg')\n",
        "plt.imshow(test_image)\n",
        "\n",
        "test_image_array=img_to_array(test_image)\n",
        "test_image_array = test_image_array / 255.0\n",
        "print(test_image_array.shape)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)\n",
        "print(test_image_array.shape)\n",
        "\n",
        "\n",
        "test_image_array = preprocess_input(test_image_array)\n",
        "predictions = model.predict(test_image_array)\n",
        "print(\"the prediction of tree count : \",predictions)\n",
        "print(' '*60)\n",
        "print(f'Prediction: {round(predictions[0][0])}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7iso1ODQ_x5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from PIL import Image\n",
        "\n",
        "# Load your trained model\n",
        "#model2 = load_model('my_model1.h5')\n",
        "\n",
        "# Load and preprocess the test image\n",
        "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
        "    with Image.open(img_path) as img:\n",
        "        img = img.resize(target_size)\n",
        "        img = img.convert('RGB')  # Ensure it's in RGB mode\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Rescale pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return preprocess_input(img_array)  # Use preprocess_input from the corresponding application module\n",
        "\n",
        "# Path to your test image\n",
        "img_path = 'test_image/test.jpg'\n",
        "\n",
        "# Preprocess the image\n",
        "test_image_array = load_and_preprocess_image(img_path)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(load_img(img_path))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Print the shape of the image array\n",
        "print(test_image_array.shape)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_image_array)\n",
        "\n",
        "# Print the prediction\n",
        "print(f'The prediction of tree count: {round(predictions[0][0])}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR0ONytiEjKX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "val_loss = model.evaluate(validation_generator, steps=validation_generator.n // validation_generator.batch_size)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions = model.predict(validation_generator, steps=validation_generator.n // validation_generator.batch_size)\n",
        "val_true = val_labels['tree_count'][:len(val_predictions)]\n",
        "\n",
        "# Compute and print metrics\n",
        "mse = mean_squared_error(val_true, val_predictions)\n",
        "mae = mean_absolute_error(val_true, val_predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Mean Absolute Error: {mae}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUzBmhD_wj7o",
        "outputId": "be68ce11-7045-4755-9f4c-13a7fd6b6737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 2 µs, total: 6 µs\n",
            "Wall time: 34.6 µs\n",
            "Found 1950 validated image filenames.\n",
            "Found 550 validated image filenames.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "15/15 [==============================] - 272s 18s/step - loss: 800.4761 - val_loss: 655.5438 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 223s 16s/step - loss: 633.7009 - val_loss: 598.1385 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 260s 18s/step - loss: 607.0005 - val_loss: 576.8295 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 262s 18s/step - loss: 610.0582 - val_loss: 563.5933 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 261s 18s/step - loss: 600.1154 - val_loss: 562.5284 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 228s 15s/step - loss: 592.2721 - val_loss: 570.3102 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 227s 15s/step - loss: 594.1062 - val_loss: 576.2078 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 268s 18s/step - loss: 595.9923 - val_loss: 573.2631 - lr: 2.0000e-04\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 231s 16s/step - loss: 594.7207 - val_loss: 569.8294 - lr: 2.0000e-04\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 234s 16s/step - loss: 587.3672 - val_loss: 570.4312 - lr: 4.0000e-05\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 266s 19s/step - loss: 597.2205 - val_loss: 569.8791 - lr: 4.0000e-05\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 268s 18s/step - loss: 589.2024 - val_loss: 572.7996 - lr: 8.0000e-06\n",
            "Epoch 13/50\n",
            " 2/15 [===>..........................] - ETA: 2:35 - loss: 571.6504"
          ]
        }
      ],
      "source": [
        "%time\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0,MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten,Dropout,DepthwiseConv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "\n",
        "# Load the augmented labels CSV file\n",
        "augmented_labels = pd.read_csv('augmented_labels.csv')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_labels, val_labels = train_test_split(augmented_labels, test_size=0.22, random_state=42)\n",
        "\n",
        "# Define the image data generator for rescaling (no further augmentation needed for training and validation)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Create a generator for the augmented training data\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_labels,\n",
        "    directory='augmented_images',\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=128,  # Use a larger batch size for training\n",
        "    class_mode='raw',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Create a generator for the validation data\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    val_labels,\n",
        "    directory='augmented_images',\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='raw',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "#base_model=create_model()\n",
        "\n",
        "\n",
        "# Model\n",
        "#InceptionV3\n",
        "\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model(inputs)\n",
        "\n",
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "\n",
        "predictions = Dense(1, activation='linear')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#print(model.summary())\n",
        "#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "#CallBacks\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0000001)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=30,\n",
        "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
        "    callbacks=[tensorboard_callback,reduce_lr_callback]#, early_stopping_callback]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ3ZY_Urx6zv",
        "outputId": "60397fb6-2fca-4241-b88d-b8fc7e666523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.06 µs\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 1s 0us/step\n",
            "Found 1950 validated image filenames.\n",
            "Found 550 validated image filenames.\n",
            "Epoch 1/30\n",
            "15/15 [==============================] - 313s 21s/step - loss: 702.6786 - val_loss: 508.4851 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "15/15 [==============================] - 320s 23s/step - loss: 437.9388 - val_loss: 335.7757 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "15/15 [==============================] - 322s 22s/step - loss: 265.5882 - val_loss: 230.3602 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "15/15 [==============================] - 311s 21s/step - loss: 168.7386 - val_loss: 165.6201 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "15/15 [==============================] - 321s 22s/step - loss: 129.7594 - val_loss: 134.6769 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "15/15 [==============================] - 325s 22s/step - loss: 102.3752 - val_loss: 109.0508 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "15/15 [==============================] - 320s 22s/step - loss: 81.5673 - val_loss: 94.2852 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "15/15 [==============================] - 303s 20s/step - loss: 66.7836 - val_loss: 86.0627 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "15/15 [==============================] - 319s 22s/step - loss: 59.8033 - val_loss: 79.3413 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "15/15 [==============================] - 301s 20s/step - loss: 53.3110 - val_loss: 69.5696 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "15/15 [==============================] - 319s 22s/step - loss: 48.1248 - val_loss: 68.2674 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "15/15 [==============================] - 318s 21s/step - loss: 45.2130 - val_loss: 60.9295 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "15/15 [==============================] - 318s 21s/step - loss: 38.2060 - val_loss: 58.1278 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "15/15 [==============================] - 305s 21s/step - loss: 35.2702 - val_loss: 53.5443 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "15/15 [==============================] - 302s 20s/step - loss: 31.8299 - val_loss: 50.5712 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "15/15 [==============================] - 302s 20s/step - loss: 29.4968 - val_loss: 52.1970 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "15/15 [==============================] - 303s 20s/step - loss: 28.5360 - val_loss: 53.4503 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "15/15 [==============================] - 332s 22s/step - loss: 26.8071 - val_loss: 50.0330 - lr: 2.0000e-04\n",
            "Epoch 19/30\n",
            "15/15 [==============================] - 332s 22s/step - loss: 25.4351 - val_loss: 47.4150 - lr: 2.0000e-04\n",
            "Epoch 20/30\n",
            "15/15 [==============================] - 329s 22s/step - loss: 24.4046 - val_loss: 48.2037 - lr: 2.0000e-04\n",
            "Epoch 21/30\n",
            "15/15 [==============================] - 321s 22s/step - loss: 23.5809 - val_loss: 47.2584 - lr: 2.0000e-04\n",
            "Epoch 22/30\n",
            "15/15 [==============================] - 320s 22s/step - loss: 23.1250 - val_loss: 46.5741 - lr: 2.0000e-04\n",
            "Epoch 23/30\n",
            "15/15 [==============================] - 319s 22s/step - loss: 22.5931 - val_loss: 46.8291 - lr: 2.0000e-04\n",
            "Epoch 24/30\n",
            "15/15 [==============================] - 318s 21s/step - loss: 21.9738 - val_loss: 46.5869 - lr: 2.0000e-04\n",
            "Epoch 25/30\n",
            "15/15 [==============================] - 302s 20s/step - loss: 21.8313 - val_loss: 46.5689 - lr: 4.0000e-05\n",
            "Epoch 26/30\n",
            "15/15 [==============================] - 304s 20s/step - loss: 21.3688 - val_loss: 45.9434 - lr: 4.0000e-05\n",
            "Epoch 27/30\n",
            "15/15 [==============================] - 316s 21s/step - loss: 21.3519 - val_loss: 46.3834 - lr: 4.0000e-05\n",
            "Epoch 28/30\n",
            "15/15 [==============================] - 299s 20s/step - loss: 21.3863 - val_loss: 46.1790 - lr: 4.0000e-05\n",
            "Epoch 29/30\n",
            "15/15 [==============================] - 303s 20s/step - loss: 21.2504 - val_loss: 46.4158 - lr: 8.0000e-06\n",
            "Epoch 30/30\n",
            "15/15 [==============================] - 307s 21s/step - loss: 21.1467 - val_loss: 44.9983 - lr: 8.0000e-06\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0,MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten,Dropout,DepthwiseConv2D, Input,GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "\n",
        "# Load the augmented labels CSV file\n",
        "augmented_labels = pd.read_csv('augmented_labels.csv')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_labels, val_labels = train_test_split(augmented_labels, test_size=0.22, random_state=42)\n",
        "\n",
        "# Define the image data generator for rescaling (no further augmentation needed for training and validation)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Create a generator for the augmented training data\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_labels,\n",
        "    directory='augmented_images',\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=128,  # Use a larger batch size for training\n",
        "    class_mode='raw',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Create a generator for the validation data\n",
        "validation_generator = datagen.flow_from_dataframe(\n",
        "    val_labels,\n",
        "    directory='augmented_images',\n",
        "    x_col='filenames',\n",
        "    y_col='tree_count',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='raw',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "#base_model=create_model()\n",
        "\n",
        "\n",
        "# Model\n",
        "#InceptionV3\n",
        "\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model(inputs)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "\n",
        "predictions = Dense(1, activation='linear')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "#print(model.summary())\n",
        "#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "#CallBacks\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
        "tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1)\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0000001)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=30,\n",
        "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
        "    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
        "    callbacks=[tensorboard_callback,reduce_lr_callback]#, early_stopping_callback]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-R7YQpLi1mY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}